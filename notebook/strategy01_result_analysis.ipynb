{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a744e16",
   "metadata": {},
   "source": [
    "# Strategy 01 Result Analysis Notebook\n",
    "This notebook loads pickled backtest outputs, computes descriptive statistics, runs simple hypothesis tests, and visualises the performance of StrategyÂ 01. Update the configuration cells as needed before executing the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c382a016",
   "metadata": {},
   "source": [
    "## 1. Set Up Environment\n",
    "Configure paths and import the libraries required for analysis and visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Configure display and plotting defaults\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Configure directories\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "DEFAULT_RESULTS_DIR = Path.home() / \"Downloads\"\n",
    "analysis_output_dir = (NOTEBOOK_DIR / \"analysis_outputs\").resolve()\n",
    "analysis_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "results_dir = DEFAULT_RESULTS_DIR\n",
    "print(f\"Notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Results directory: {results_dir}\")\n",
    "print(f\"Analysis outputs will be stored in: {analysis_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d2c14",
   "metadata": {},
   "source": [
    "## 2. Discover Result Files\n",
    "Locate pickled result files (simulation, holdings, revenue) under the results directory to decide which dataset to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "RESULT_FILE_PATTERNS = {\n",
    "    \"simulation\": \"simulation_results_*.pkl\",\n",
    "    \"holdings\": \"shares_owned_*.pkl\",\n",
    "    \"revenue\": \"revenue_records_*.pkl\",\n",
    "}\n",
    "\n",
    "def discover_result_files(root: Path) -> pd.DataFrame:\n",
    "    records: list[dict[str, Any]] = []\n",
    "    for kind, pattern in RESULT_FILE_PATTERNS.items():\n",
    "        for path in root.glob(pattern):\n",
    "            prefix = path.stem.split(\"_\")[-1]\n",
    "            records.append({\n",
    "                \"kind\": kind,\n",
    "                \"prefix\": prefix,\n",
    "                \"path\": path.resolve(),\n",
    "                \"modified\": pd.Timestamp(path.stat().st_mtime, unit=\"s\"),\n",
    "                \"size_kb\": path.stat().st_size / 1024,\n",
    "            })\n",
    "    return pd.DataFrame(records).sort_values([\"prefix\", \"kind\"])\n",
    "\n",
    "discovered_files = discover_result_files(results_dir)\n",
    "if discovered_files.empty:\n",
    "    print(\"No result files were found. Update `results_dir` above and rerun this cell.\")\n",
    "else:\n",
    "    display(discovered_files.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05efb839",
   "metadata": {},
   "source": [
    "## 3. Load and Combine Result Data\n",
    "Select a prefix to analyse, read the relevant pickles, and convert them into tabular pandas structures for downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path: Path) -> Any:\n",
    "    with open(path, \"rb\") as fh:\n",
    "        return pickle.load(fh)\n",
    "\n",
    "def flatten_simulation(simulation: dict[str, list[dict[str, Any]]]) -> pd.DataFrame:\n",
    "    records: list[dict[str, Any]] = []\n",
    "    for ticker, rows in simulation.items():\n",
    "        for row in rows:\n",
    "            record = row.copy()\n",
    "            record[\"ticker\"] = ticker\n",
    "            records.append(record)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def flatten_holdings(holdings: dict[str, list[dict[str, Any]]]) -> pd.DataFrame:\n",
    "    records: list[dict[str, Any]] = []\n",
    "    for ticker, rows in holdings.items():\n",
    "        for row in rows:\n",
    "            record = row.copy()\n",
    "            record[\"ticker\"] = ticker\n",
    "            records.append(record)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def flatten_revenue(revenue: dict[str, list[dict[str, Any]]]) -> pd.DataFrame:\n",
    "    records: list[dict[str, Any]] = []\n",
    "    for ticker, rows in revenue.items():\n",
    "        for row in rows:\n",
    "            record = row.copy()\n",
    "            record[\"ticker\"] = ticker\n",
    "            records.append(record)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "if discovered_files.empty:\n",
    "    print(\"Populate `results_dir` with pickled backtest outputs before continuing.\")\n",
    "    simulation_df = pd.DataFrame()\n",
    "    holdings_df = pd.DataFrame()\n",
    "    revenue_df = pd.DataFrame()\n",
    "else:\n",
    "    available_prefixes = discovered_files[\"prefix\"].unique().tolist()\n",
    "    target_prefix = available_prefixes[0]\n",
    "    print(f\"Available prefixes: {available_prefixes}\")\n",
    "    print(f\"Using prefix: {target_prefix}\")\n",
    "\n",
    "    paths = {\n",
    "        row.kind: row.path for row in discovered_files.itertuples() if row.prefix == target_prefix\n",
    "    }\n",
    "\n",
    "    simulation_df = flatten_simulation(load_pickle(paths[\"simulation\"])) if \"simulation\" in paths else pd.DataFrame()\n",
    "    holdings_df = flatten_holdings(load_pickle(paths[\"holdings\"])) if \"holdings\" in paths else pd.DataFrame()\n",
    "    revenue_df = flatten_revenue(load_pickle(paths[\"revenue\"])) if \"revenue\" in paths else pd.DataFrame()\n",
    "\n",
    "    print(\"Loaded frames:\")\n",
    "    print({\n",
    "        \"simulation\": simulation_df.shape,\n",
    "        \"holdings\": holdings_df.shape,\n",
    "        \"revenue\": revenue_df.shape,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826eef97",
   "metadata": {},
   "source": [
    "## 4. Clean and Prepare Data\n",
    "Enforce data types, drop malformed rows, and compute convenience fields for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19938615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_simulation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    df[\"simuldate\"] = pd.to_datetime(df[\"simuldate\"], errors=\"coerce\")\n",
    "    numeric_fields = [\"invest_amount\", \"shares_bought\", \"vwap_stability\", \"popularity\"]\n",
    "    for field in numeric_fields:\n",
    "        if field in df.columns:\n",
    "            df[field] = pd.to_numeric(df[field], errors=\"coerce\")\n",
    "    df.dropna(subset=[\"simuldate\", \"ticker\"], inplace=True)\n",
    "    df.sort_values([\"ticker\", \"simuldate\"], inplace=True)\n",
    "    df[\"invest_amount\"].fillna(0, inplace=True) if \"invest_amount\" in df else None\n",
    "    df[\"shares_bought\"].fillna(0, inplace=True) if \"shares_bought\" in df else None\n",
    "    df[\"invest_flag\"].fillna(\"no_action\", inplace=True) if \"invest_flag\" in df else None\n",
    "    return df\n",
    "\n",
    "def prepare_holdings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    for col in [\"buy_date\", \"sold_date\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "    for col in [\"shares\", \"buy_price\", \"sold_price\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df.dropna(subset=[\"ticker\", \"buy_date\", \"shares\"], inplace=True)\n",
    "    df[\"holding_days\"] = (df[\"sold_date\"] - df[\"buy_date\"]).dt.days\n",
    "    return df\n",
    "\n",
    "def prepare_revenue(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    if \"sell_date\" in df.columns:\n",
    "        df[\"sell_date\"] = pd.to_datetime(df[\"sell_date\"], errors=\"coerce\")\n",
    "    for col in [\"revenue\", \"shares_sold\", \"sold_price\", \"bought_price\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df.dropna(subset=[\"ticker\", \"sell_date\", \"revenue\"], inplace=True)\n",
    "    df[\"profit_pct\"] = np.where(\n",
    "    (df[\"bought_price\"] > 0),\n",
    "        (df[\"sold_price\"] - df[\"bought_price\"]) / df[\"bought_price\"],\n",
    "        np.nan,\n",
    "    ) if \"bought_price\" in df.columns and \"sold_price\" in df.columns else np.nan\n",
    "    return df\n",
    "\n",
    "simulation_df = prepare_simulation(simulation_df)\n",
    "holdings_df = prepare_holdings(holdings_df)\n",
    "revenue_df = prepare_revenue(revenue_df)\n",
    "\n",
    "print({\n",
    "    \"simulation\": simulation_df.shape,\n",
    "    \"holdings\": holdings_df.shape,\n",
    "    \"revenue\": revenue_df.shape,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b19911",
   "metadata": {},
   "source": [
    "## 5. Compute Descriptive Statistics\n",
    "Produce overview tables and correlation heatmaps to understand the distribution of key strategy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fac6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if simulation_df.empty:\n",
    "    print(\"Simulation DataFrame empty; skip descriptive statistics.\")\n",
    "else:\n",
    "    display(simulation_df.describe(include=\"all\").transpose())\n",
    "\n",
    "    grouped_summary = (\n",
    "        simulation_df.groupby(\"ticker\")[\"invest_amount\"].agg([\n",
    "            (\"trades\", \"count\"),\n",
    "            (\"invest_total\", \"sum\"),\n",
    "            (\"invest_mean\", \"mean\"),\n",
    "        ])\n",
    "    )\n",
    "    display(grouped_summary.sort_values(\"invest_total\", ascending=False))\n",
    "\n",
    "    numeric_cols = simulation_df.select_dtypes(include=[np.number])\n",
    "    if not numeric_cols.empty:\n",
    "        corr = numeric_cols.corr()\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "        plt.title(\"Correlation Matrix (Simulation Metrics)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "if revenue_df.empty:\n",
    "    print(\"Revenue DataFrame empty; skipping revenue stats.\")\n",
    "else:\n",
    "    revenue_summary = revenue_df.groupby(\"ticker\")[\"revenue\"].agg([\"count\", \"sum\", \"mean\", \"median\"])\n",
    "    display(revenue_summary.sort_values(\"sum\", ascending=False))\n",
    "\n",
    "    if \"profit_pct\" in revenue_df.columns and revenue_df[\"profit_pct\"].notna().any():\n",
    "        profit_stats = revenue_df[\"profit_pct\"].describe(percentiles=[0.25, 0.5, 0.75])\n",
    "        display(profit_stats.to_frame(name=\"profit_pct\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ee676",
   "metadata": {},
   "source": [
    "## 6. Run Statistical Tests\n",
    "Evaluate whether revenues differ significantly from zero and compare profitability between tickers using SciPy hypothesis tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e75ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_test_results: list[dict[str, Any]] = []\n",
    "\n",
    "if revenue_df.empty:\n",
    "    print(\"Revenue data unavailable; skipping hypothesis tests.\")\n",
    "else:\n",
    "    revenues = revenue_df[\"revenue\"].dropna()\n",
    "    if len(revenues) > 1:\n",
    "        t_stat, p_value = stats.ttest_1samp(revenues, popmean=0)\n",
    "        stat_test_results.append({\n",
    "            \"test\": \"one-sample t-test\",\n",
    "            \"statistic\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"n\": len(revenues),\n",
    "        })\n",
    "        print(f\"One-sample t-test vs zero revenue: t={t_stat:.3f}, p={p_value:.4f}, n={len(revenues)}\")\n",
    "    else:\n",
    "        print(\"Not enough revenue observations for t-test.\")\n",
    "\n",
    "    if \"profit_pct\" in revenue_df.columns:\n",
    "        groups = [\n",
    "            grp.dropna().values\n",
    "            for _, grp in revenue_df.groupby(\"ticker\")[\"profit_pct\"]\n",
    "            if grp.dropna().shape[0] > 1\n",
    "        ]\n",
    "        if len(groups) >= 2:\n",
    "            f_stat, p_value = stats.f_oneway(*groups)\n",
    "            stat_test_results.append({\n",
    "                \"test\": \"one-way ANOVA (profit_pct by ticker)\",\n",
    "                \"statistic\": f_stat,\n",
    "                \"p_value\": p_value,\n",
    "                \"groups\": len(groups),\n",
    "            })\n",
    "            print(f\"ANOVA across tickers (profit_pct): F={f_stat:.3f}, p={p_value:.4f}, groups={len(groups)}\")\n",
    "        else:\n",
    "            print(\"Not enough ticker groups for ANOVA.\")\n",
    "\n",
    "if stat_test_results:\n",
    "    display(pd.DataFrame(stat_test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52216691",
   "metadata": {},
   "source": [
    "## 7. Generate Distribution Charts\n",
    "Visualise the distributions of trade revenues and holding durations with histograms, KDE curves, and box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f7d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if revenue_df.empty:\n",
    "    print(\"Revenue data unavailable; skipping distribution plots.\")\n",
    "else:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(revenue_df[\"revenue\"], kde=True, bins=30)\n",
    "    plt.axvline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(\"Revenue Distribution\")\n",
    "    plt.xlabel(\"Revenue (KRW)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if \"profit_pct\" in revenue_df.columns and revenue_df[\"profit_pct\"].notna().any():\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.kdeplot(revenue_df[\"profit_pct\"].dropna(), shade=True)\n",
    "        plt.title(\"Profit Percentage KDE\")\n",
    "        plt.xlabel(\"Profit %\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=revenue_df, x=\"ticker\", y=\"revenue\")\n",
    "    plt.title(\"Revenue by Ticker\")\n",
    "    plt.xlabel(\"Ticker\")\n",
    "    plt.ylabel(\"Revenue (KRW)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if holdings_df.empty:\n",
    "    print(\"Holdings data unavailable; skipping holding duration plots.\")\n",
    "else:\n",
    "    if \"holding_days\" in holdings_df.columns and holdings_df[\"holding_days\"].notna().any():\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.histplot(holdings_df[\"holding_days\"].dropna(), kde=True, bins=20)\n",
    "        plt.title(\"Holding Duration Distribution\")\n",
    "        plt.xlabel(\"Holding Days\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea6861e",
   "metadata": {},
   "source": [
    "## 8. Create Comparative Visualizations\n",
    "Build time-series and cross-sectional plots to compare performance across tickers and simulation dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eec705",
   "metadata": {},
   "outputs": [],
   "source": [
    "if revenue_df.empty:\n",
    "    print(\"Revenue data unavailable; skipping comparative visuals.\")\n",
    "else:\n",
    "    revenue_by_date = (\n",
    "        revenue_df.groupby(\"sell_date\")[\"revenue\"].sum().sort_index().cumsum().rename(\"cumulative_revenue\")\n",
    "    )\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(revenue_by_date.index, revenue_by_date.values)\n",
    "    plt.title(\"Cumulative Revenue Over Time\")\n",
    "    plt.xlabel(\"Sell Date\")\n",
    "    plt.ylabel(\"Cumulative Revenue (KRW)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    revenue_per_ticker = revenue_df.groupby(\"ticker\")[\"revenue\"].sum().sort_values(ascending=False)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=revenue_per_ticker.index, y=revenue_per_ticker.values)\n",
    "    plt.title(\"Total Revenue by Ticker\")\n",
    "    plt.xlabel(\"Ticker\")\n",
    "    plt.ylabel(\"Total Revenue (KRW)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if simulation_df.empty:\n",
    "    print(\"Simulation data unavailable; skipping scatter plots.\")\n",
    "else:\n",
    "    if {\"invest_amount\", \"popularity\"}.issubset(simulation_df.columns):\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.scatterplot(data=simulation_df, x=\"popularity\", y=\"invest_amount\", hue=\"ticker\", alpha=0.6)\n",
    "        plt.title(\"Investment Size vs Popularity Signal\")\n",
    "        plt.xlabel(\"Volume Popularity Signal\")\n",
    "        plt.ylabel(\"Invest Amount\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if {\"simuldate\", \"invest_amount\"}.issubset(simulation_df.columns):\n",
    "        invest_over_time = simulation_df.groupby(\"simuldate\")[\"invest_amount\"].sum().sort_index()\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(invest_over_time.index, invest_over_time.values)\n",
    "        plt.title(\"Aggregate Invest Amount Over Simulation Dates\")\n",
    "        plt.xlabel(\"Simulation Date\")\n",
    "        plt.ylabel(\"Invest Amount (KRW)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceadfb60",
   "metadata": {},
   "source": [
    "## 9. Export Analysis Artifacts\n",
    "Persist processed datasets, statistics, and test outcomes so they can be reused outside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85602c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_prefix = (f\"{target_prefix}_analysis\" if \"target_prefix\" in locals() else \"strategy01_analysis\")\n",
    "export_paths: dict[str, Path] = {}\n",
    "\n",
    "if not simulation_df.empty:\n",
    "    simulation_csv = analysis_output_dir / f\"{export_prefix}_simulation.csv\"\n",
    "    simulation_df.to_csv(simulation_csv, index=False)\n",
    "    export_paths[\"simulation_csv\"] = simulation_csv\n",
    "\n",
    "if not revenue_df.empty:\n",
    "    revenue_csv = analysis_output_dir / f\"{export_prefix}_revenue.csv\"\n",
    "    revenue_df.to_csv(revenue_csv, index=False)\n",
    "    export_paths[\"revenue_csv\"] = revenue_csv\n",
    "\n",
    "    revenue_summary = revenue_df.groupby(\"ticker\")[\"revenue\"].agg([\"count\", \"sum\", \"mean\", \"median\"])\n",
    "    summary_csv = analysis_output_dir / f\"{export_prefix}_revenue_summary.csv\"\n",
    "    revenue_summary.to_csv(summary_csv)\n",
    "    export_paths[\"revenue_summary_csv\"] = summary_csv\n",
    "\n",
    "if stat_test_results:\n",
    "    stats_json = analysis_output_dir / f\"{export_prefix}_stat_tests.json\"\n",
    "    with open(stats_json, \"w\", encoding=\"utf-8\") as fh:\n",
    "        json.dump(stat_test_results, fh, indent=2, default=str)\n",
    "    export_paths[\"stat_tests_json\"] = stats_json\n",
    "\n",
    "if export_paths:\n",
    "    print(\"Exported the following artifacts:\")\n",
    "    for label, path in export_paths.items():\n",
    "        print(f\"- {label}: {path}\")\n",
    "else:\n",
    "    print(\"No artifacts were exported. Ensure data frames are populated before running this cell.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
