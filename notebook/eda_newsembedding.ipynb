{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d00155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d7929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(r\"/rdrive/workspace/perfectdays/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedb806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWS_PARQUET_MONTH_DIR = os.environ[\"NEWS_PARQUET_MONTH_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a9784cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/rdrive/rtrs_news/monthly/1999-03_embeddings_3pty_ko.npz',\n",
       " '/rdrive/rtrs_news/monthly/1999-04_embeddings_3pty_ko.npz',\n",
       " '/rdrive/rtrs_news/monthly/1999-05_embeddings_3pty_ko.npz',\n",
       " '/rdrive/rtrs_news/monthly/1999-06_embeddings_3pty_ko.npz',\n",
       " '/rdrive/rtrs_news/monthly/1999-07_embeddings_3pty_ko.npz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmfiles = sorted(glob.glob(os.path.join(NEWS_PARQUET_MONTH_DIR, \"*3pty_ko.npz\")))\n",
    "mmfiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc55d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmfile = mmfiles[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d212a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read npz file\n",
    "mm_data = np.load(mmfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5db0483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(NpzFile '/rdrive/rtrs_news/monthly/2025-10_embeddings_3pty_ko.npz' with keys: ids, embeddings)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e31d36eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: (173580,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# print shape of each array\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m mm_data.keys():\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmm_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)   \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rdrive_pvc/Env/openaioss/lib64/python3.11/site-packages/numpy/lib/_npyio_impl.py:257\u001b[39m, in \u001b[36mNpzFile.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mbytes\u001b[39m.seek(\u001b[32m0\u001b[39m)\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m magic == \u001b[38;5;28mformat\u001b[39m.MAGIC_PREFIX:\n\u001b[32m    249\u001b[39m     \u001b[38;5;66;03m# FIXME: This seems like it will copy strings around\u001b[39;00m\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m#   more than is strictly necessary.  The zipfile\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    255\u001b[39m     \u001b[38;5;66;03m#   (or at least uncompress) the data\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;66;03m#   directly into the array memory.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_header_size\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rdrive_pvc/Env/openaioss/lib64/python3.11/site-packages/numpy/lib/_format_impl.py:869\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    867\u001b[39m             read_count = \u001b[38;5;28mmin\u001b[39m(max_read_count, count - i)\n\u001b[32m    868\u001b[39m             read_size = \u001b[38;5;28mint\u001b[39m(read_count * dtype.itemsize)\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m             data = \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marray data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    870\u001b[39m             array[i:i + read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[32m    871\u001b[39m                                                      count=read_count)\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m array.size != count:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/rdrive_pvc/Env/openaioss/lib64/python3.11/site-packages/numpy/lib/_format_impl.py:1013\u001b[39m, in \u001b[36m_read_bytes\u001b[39m\u001b[34m(fp, size, error_template)\u001b[39m\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1009\u001b[39m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[32m   1010\u001b[39m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[32m   1011\u001b[39m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[32m   1012\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m         r = \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m         data += r\n\u001b[32m   1015\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) == size:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.11/zipfile.py:966\u001b[39m, in \u001b[36mZipExtFile.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    964\u001b[39m \u001b[38;5;28mself\u001b[39m._offset = \u001b[32m0\u001b[39m\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    967\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[32m    968\u001b[39m         \u001b[38;5;28mself\u001b[39m._readbuffer = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.11/zipfile.py:1034\u001b[39m, in \u001b[36mZipExtFile._read1\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1032\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._decompressor.unconsumed_tail\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n > \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         data += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._read2(n)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.11/zipfile.py:1066\u001b[39m, in \u001b[36mZipExtFile._read2\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1063\u001b[39m n = \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m.MIN_READ_SIZE)\n\u001b[32m   1064\u001b[39m n = \u001b[38;5;28mmin\u001b[39m(n, \u001b[38;5;28mself\u001b[39m._compress_left)\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fileobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28mself\u001b[39m._compress_left -= \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[32m   1068\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.11/zipfile.py:786\u001b[39m, in \u001b[36m_SharedFile.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    782\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt read from the ZIP file while there \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    783\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis an open writing handle on it. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    784\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mClose the writing handle before trying to read.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    785\u001b[39m \u001b[38;5;28mself\u001b[39m._file.seek(\u001b[38;5;28mself\u001b[39m._pos)\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m data = \u001b[38;5;28mself\u001b[39m._file.read(n)\n\u001b[32m    787\u001b[39m \u001b[38;5;28mself\u001b[39m._pos = \u001b[38;5;28mself\u001b[39m._file.tell()\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# print shape of each array\n",
    "for key in mm_data.keys():\n",
    "    print(f\"{key}: {mm_data[key].shape}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e00e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge id and embedding into a dataframe\n",
    "mm_df = pl.DataFrame({\n",
    "    \"id\": mm_data[\"ids\"],\n",
    "    \"embedding\": [emb for emb in mm_data[\"embeddings\"]]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ca83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (173_580, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>embedding</th></tr><tr><td>i64</td><td>array[f32, 768]</td></tr></thead><tbody><tr><td>0</td><td>[0.00873, -0.014797, … -0.004965]</td></tr><tr><td>1</td><td>[0.014095, -0.009662, … 0.000396]</td></tr><tr><td>2</td><td>[0.021123, 0.010042, … 0.02011]</td></tr><tr><td>3</td><td>[0.01345, -0.01291, … 0.005197]</td></tr><tr><td>4</td><td>[0.005833, -0.001751, … -0.020308]</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>173575</td><td>[0.002113, -0.013208, … -0.000254]</td></tr><tr><td>173576</td><td>[0.031447, -0.00351, … 0.006743]</td></tr><tr><td>173577</td><td>[0.031447, -0.00351, … 0.006743]</td></tr><tr><td>173578</td><td>[0.031027, -0.003222, … 0.005619]</td></tr><tr><td>173579</td><td>[0.019834, -0.005489, … 0.000278]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (173_580, 2)\n",
       "┌────────┬─────────────────────────────────┐\n",
       "│ id     ┆ embedding                       │\n",
       "│ ---    ┆ ---                             │\n",
       "│ i64    ┆ array[f32, 768]                 │\n",
       "╞════════╪═════════════════════════════════╡\n",
       "│ 0      ┆ [0.00873, -0.014797, … -0.0049… │\n",
       "│ 1      ┆ [0.014095, -0.009662, … 0.0003… │\n",
       "│ 2      ┆ [0.021123, 0.010042, … 0.02011… │\n",
       "│ 3      ┆ [0.01345, -0.01291, … 0.005197… │\n",
       "│ 4      ┆ [0.005833, -0.001751, … -0.020… │\n",
       "│ …      ┆ …                               │\n",
       "│ 173575 ┆ [0.002113, -0.013208, … -0.000… │\n",
       "│ 173576 ┆ [0.031447, -0.00351, … 0.00674… │\n",
       "│ 173577 ┆ [0.031447, -0.00351, … 0.00674… │\n",
       "│ 173578 ┆ [0.031027, -0.003222, … 0.0056… │\n",
       "│ 173579 ┆ [0.019834, -0.005489, … 0.0002… │\n",
       "└────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3bf4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173580, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6792a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsfile = os.path.join(NEWS_PARQUET_MONTH_DIR, '2025-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb4b5b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>version_created</th>\n",
       "      <th>title</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>subject_qcodes</th>\n",
       "      <th>content</th>\n",
       "      <th>src</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tag:reuters.com,2025-10-01:newsml_BwHJtdMa:1</td>\n",
       "      <td>2025-10-01T00:00:00.078Z</td>\n",
       "      <td>VFC INVESTORS: Kirby McInerney LLP Reminds V.F...</td>\n",
       "      <td>en</td>\n",
       "      <td>B:1221, B:1323, B:195, B:234, B:239, B:242, B:...</td>\n",
       "      <td>For best results when printing this announceme...</td>\n",
       "      <td>3PTY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tag:reuters.com,2025-10-01:newsml_Bw2HLJs9a:1</td>\n",
       "      <td>2025-10-01T00:00:00.116Z</td>\n",
       "      <td>Thermo Fisher Scientific Prices Offering of US...</td>\n",
       "      <td>en</td>\n",
       "      <td>A:2, B:148, B:149, B:150, B:151, B:156, B:1700...</td>\n",
       "      <td>For best results when printing this announceme...</td>\n",
       "      <td>3PTY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            guid           version_created  \\\n",
       "0   tag:reuters.com,2025-10-01:newsml_BwHJtdMa:1  2025-10-01T00:00:00.078Z   \n",
       "1  tag:reuters.com,2025-10-01:newsml_Bw2HLJs9a:1  2025-10-01T00:00:00.116Z   \n",
       "\n",
       "                                               title lang_code  \\\n",
       "0  VFC INVESTORS: Kirby McInerney LLP Reminds V.F...        en   \n",
       "1  Thermo Fisher Scientific Prices Offering of US...        en   \n",
       "\n",
       "                                      subject_qcodes  \\\n",
       "0  B:1221, B:1323, B:195, B:234, B:239, B:242, B:...   \n",
       "1  A:2, B:148, B:149, B:150, B:151, B:156, B:1700...   \n",
       "\n",
       "                                             content   src ids  \n",
       "0  For best results when printing this announceme...  3PTY   0  \n",
       "1  For best results when printing this announceme...  3PTY   1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews = pd.read_parquet(newsfile)\n",
    "dfnews['ids'] = dfnews.index.astype(str)\n",
    "dfnews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8de0af4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1736, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling 1% of dfnews\n",
    "dfnews = dfnews[(dfnews['lang_code'] == 'ko') & (dfnews['src'] == '3PTY')]\n",
    "# 1% sampling\n",
    "dfnews = dfnews.sample(frac=0.01, random_state=42)\n",
    "dfnews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b9820d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>version_created</th>\n",
       "      <th>title</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>subject_qcodes</th>\n",
       "      <th>content</th>\n",
       "      <th>src</th>\n",
       "      <th>ids</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1785758</th>\n",
       "      <td>tag:reuters.com,2025-10-16:newsml_EDYG00389:1</td>\n",
       "      <td>2025-10-16T22:48:44.801Z</td>\n",
       "      <td>[AI시그널] 티에프이, 상승세 지속 중 거래량 증가로 긍정적 신호</td>\n",
       "      <td>ko</td>\n",
       "      <td>B:163, B:164, B:1740, B:278, B:279, G:1, G:6, ...</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n        [이데일리 이머니 기자] 기술적 ...</td>\n",
       "      <td>3PTY</td>\n",
       "      <td>1785758</td>\n",
       "      <td>[AI시그널] 티에프이, 상승세 지속 중 거래량 증가로 긍정적 신호\\n\\n\\r\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013268</th>\n",
       "      <td>tag:reuters.com,2025-10-18:newsml_EDYI00023:2</td>\n",
       "      <td>2025-10-18T23:23:55.309Z</td>\n",
       "      <td>고1 ‘성적 인플레’ 심화…내신 경쟁 ‘원점수’까지 확대</td>\n",
       "      <td>ko</td>\n",
       "      <td>M:1QD, M:2CX</td>\n",
       "      <td>- 내신 9등급→ 5등급 개편되며 변별력 약화\\r\\n- 학생 간 내신 경쟁 ‘등급’...</td>\n",
       "      <td>3PTY</td>\n",
       "      <td>2013268</td>\n",
       "      <td>고1 ‘성적 인플레’ 심화…내신 경쟁 ‘원점수’까지 확대\\n\\n- 내신 9등급→ 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  guid  \\\n",
       "1785758  tag:reuters.com,2025-10-16:newsml_EDYG00389:1   \n",
       "2013268  tag:reuters.com,2025-10-18:newsml_EDYI00023:2   \n",
       "\n",
       "                  version_created                                  title  \\\n",
       "1785758  2025-10-16T22:48:44.801Z  [AI시그널] 티에프이, 상승세 지속 중 거래량 증가로 긍정적 신호   \n",
       "2013268  2025-10-18T23:23:55.309Z        고1 ‘성적 인플레’ 심화…내신 경쟁 ‘원점수’까지 확대   \n",
       "\n",
       "        lang_code                                     subject_qcodes  \\\n",
       "1785758        ko  B:163, B:164, B:1740, B:278, B:279, G:1, G:6, ...   \n",
       "2013268        ko                                       M:1QD, M:2CX   \n",
       "\n",
       "                                                   content   src      ids  \\\n",
       "1785758  \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n        [이데일리 이머니 기자] 기술적 ...  3PTY  1785758   \n",
       "2013268  - 내신 9등급→ 5등급 개편되며 변별력 약화\\r\\n- 학생 간 내신 경쟁 ‘등급’...  3PTY  2013268   \n",
       "\n",
       "                                                      text  \n",
       "1785758  [AI시그널] 티에프이, 상승세 지속 중 거래량 증가로 긍정적 신호\\n\\n\\r\\n\\...  \n",
       "2013268  고1 ‘성적 인플레’ 심화…내신 경쟁 ‘원점수’까지 확대\\n\\n- 내신 9등급→ 5...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews['text'] = dfnews.apply(lambda x: x['title'] + '\\n\\n' + x['content'], axis=1)\n",
    "dfnews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6f1fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rdrive_pvc/Env/openaioss/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 12/12 [00:28<00:00,  2.37s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': \"## Quantum Mechanics: Explained Simply\\n\\nQuantum mechanics is the physics of the **very small** - atoms and the particles *within* them. It's weird, counterintuitive, but incredibly successful at explaining how the universe works at that level. Here's the gist:\\n\\n**1. Quantization:** Energy, like light and electricity, isn't continuous. It comes in tiny, discrete packets called **quanta**. Think of it like stairs vs. a ramp - you can only stand on specific steps (quanta) not anywhere in between.\\n\\n**2. Wave-Particle Duality:**  Particles (like electrons) can behave like waves, and waves (like light) can behave like particles. It's not *either/or*, it's *both*.  Imagine something that spreads out like a wave, but also hits a target like a particle.\\n\\n**3. Uncertainty:** There's a fundamental limit to how precisely we can know certain pairs of properties simultaneously.  The most famous example is **Heisenberg's Uncertainty Principle**: the more accurately you know a particle's position, the less accurately you know its momentum (and vice versa).  It's not a limitation of our instruments, it's a property of\"}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "#usloth oss 120\n",
    "# model_id = r'/rdrive_pvc/huggingface_cache/hub/models--unsloth--gpt-oss-120b/snapshots/212ea6d47b66c92f5bfd27956ef07bc160f5ea68'\n",
    "#openai oss 20\n",
    "# model_id = r'/rdrive_pvc/huggingface_cache/hub/models--openai--gpt-oss-20b/snapshots/2e8f8052ee2aeee907f76e08c08b9fdde8677ca8'\n",
    "\n",
    "# gemma 27-it\n",
    "model_id = r'/rdrive_pvc/huggingface_cache/hub/models--google--gemma-3-27b-it/snapshots/005ad3404e59d6023443cb575daa05336842228a'\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"cuda:0\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Explain quantum mechanics clearly and concisely.\"},\n",
    "]\n",
    "\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad8c51",
   "metadata": {},
   "source": [
    "## Financial Sentiment Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5028f5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompt = (\n",
    "    \"You are a bilingual (Korean/English) financial market analyst. Read the Korean news excerpt and assess the expected market impact on affected financial assets. \"\n",
    "    \"Follow the instructions precisely and return only strict JSON.\\n\"\n",
    "    \"\\nTask\\n\"\n",
    "    \"1) Classify sentiment using ONLY one of: very positive, positive, neutral, negative, very negative.\\n\"\n",
    "    \"2) Base your decision on expected near-term market impact (equity prices, credit spreads/default risk, FX, interest rates, macro risk).\\n\"\n",
    "    \"3) Provide a single-sentence justification under 50 words that cites concrete drivers (e.g., earnings/guidance, regulation, policy, demand/supply, prices, FX, rates, geopolitics, disruptions).\\n\"\n",
    "    \"4) Identify the most relevant NAICS industry code(s) mentioned or clearly implied. Use the most specific 6-digit codes when possible. Include the code and its label in the form \\\"CODE - Label\\\". If unclear, return an empty array []. Limit to up to 3 entries.\\n\"\n",
    "    \"5) List directly mentioned or clearly implicated company names (Korean or English official names). Do not guess. If none, return an empty array [].\\n\"\n",
    "    \"\\nLabeling guidance (be conservative)\\n\"\n",
    "    \"- very positive: strong broad upside (e.g., beat + raised guidance, major policy support, material cost relief) likely to lift assets.\\n\"\n",
    "    \"- positive: modest upside or favorable development.\\n\"\n",
    "    \"- neutral: limited, mixed, or insufficient information.\\n\"\n",
    "    \"- negative: modest downside (e.g., miss, mild regulatory risk, soft demand).\\n\"\n",
    "    \"- very negative: severe downside (e.g., default/bankruptcy risk, sanctions, major accidents, sharp demand collapse).\\n\"\n",
    "    \"\\nFormatting rules\\n\"\n",
    "    \"- Output must be STRICT JSON with keys: sentiment, justification, related_industry_naics, related_company_names.\\n\"\n",
    "    \"- Values: sentiment = string; justification = string (<50 words); related_industry_naics = array of strings; related_company_names = array of strings.\\n\"\n",
    "    \"- No extra text, explanations, comments, or markdown. JSON only.\\n\"\n",
    "    \"- If the article is in Korean, you may write the justification in Korean or English; keep it concise and factual.\\n\"\n",
    "    \"\\nExample response\\n\"\n",
    "    \"{{\\n\"\n",
    "    \"  \\\"sentiment\\\": \\\"very negative\\\",\\n\"\n",
    "    \"  \\\"justification\\\": \\\"수출 감소와 가격 하락이 예고되며 마진 압박이 커져 단기 주가와 신용 스프레드에 부정적.\\\",\\n\"\n",
    "    \"  \\\"related_industry_naics\\\": [\\\"334413 - Semiconductor and Related Device Manufacturing\\\"],\\n\"\n",
    "    \"  \\\"related_company_names\\\": [\\\"Samsung Electronics\\\", \\\"SK hynix\\\"]\\n\"\n",
    "    \"}}\\n\"\n",
    "    \"\\nText: {text}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46eb42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_sentiment(text: str) -> dict[str, object]:\n",
    "    allowed = {\"very positive\", \"positive\", \"very negative\", \"negative\", \"neutral\"}\n",
    "\n",
    "    def normalize_sentiment(s: str) -> str:\n",
    "        s = (s or \"\").strip().lower()\n",
    "        mapping = {\n",
    "            \"very positive\": \"very positive\",\n",
    "            \"positive\": \"positive\",\n",
    "            \"very negative\": \"very negative\",\n",
    "            \"negative\": \"negative\",\n",
    "            \"neutral\": \"neutral\",\n",
    "            \"pos\": \"positive\",\n",
    "            \"neg\": \"negative\",\n",
    "            \"bullish\": \"positive\",\n",
    "            \"bearish\": \"negative\",\n",
    "            \"unknown\": \"neutral\",\n",
    "            \"error\": \"neutral\",\n",
    "        }\n",
    "        return mapping.get(s, \"neutral\")\n",
    "\n",
    "    def trim_words(s: str, max_words: int = 50) -> str:\n",
    "        if not isinstance(s, str):\n",
    "            return \"\"\n",
    "        words = s.strip().split()\n",
    "        return s.strip() if len(words) <= max_words else \" \".join(words[:max_words])\n",
    "\n",
    "    def to_string_list(val) -> list[str]:\n",
    "        if val is None:\n",
    "            return []\n",
    "        if isinstance(val, list):\n",
    "            out = []\n",
    "            for x in val:\n",
    "                if isinstance(x, (str, int, float)):\n",
    "                    out.append(str(x))\n",
    "            return out\n",
    "        if isinstance(val, (str, int, float)):\n",
    "            return [str(val)]\n",
    "        return []\n",
    "\n",
    "    def make_fallback(justification: str) -> dict[str, object]:\n",
    "        return {\n",
    "            \"sentiment\": \"neutral\",\n",
    "            \"justification\": trim_words(justification, 50),\n",
    "            \"related_industry_naics\": [],\n",
    "            \"related_company_names\": [],\n",
    "        }\n",
    "\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return make_fallback(\"Input text missing or empty.\")\n",
    "\n",
    "    safe_text = text.replace(\"{\", \"{{\").replace(\"}\", \"}}\").strip()\n",
    "    # Avoid str.format to prevent KeyError from JSON braces in the prompt\n",
    "    prompt_content = sentiment_prompt.replace(\"{text}\", safe_text)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_content},\n",
    "    ]\n",
    "    try:\n",
    "        outputs = pipe(messages, max_new_tokens=256)\n",
    "    except Exception as exc:\n",
    "        return make_fallback(f\"Pipeline failure: {exc}\")\n",
    "\n",
    "    # Extract model content robustly\n",
    "    content = \"\"\n",
    "    try:\n",
    "        gen = outputs[0].get(\"generated_text\", \"\")\n",
    "        if isinstance(gen, list):\n",
    "            last = gen[-1]\n",
    "            if isinstance(last, dict) and \"content\" in last:\n",
    "                content = (last[\"content\"] or \"\").strip()\n",
    "            else:\n",
    "                content = (str(last) or \"\").strip()\n",
    "        elif isinstance(gen, dict) and \"content\" in gen:\n",
    "            content = (gen[\"content\"] or \"\").strip()\n",
    "        elif isinstance(gen, str):\n",
    "            content = gen.strip()\n",
    "        else:\n",
    "            content = (str(gen) or \"\").strip()\n",
    "    except Exception as exc:\n",
    "        return make_fallback(f\"Malformed pipeline output: {exc}\")\n",
    "\n",
    "    # Parse JSON strictly; if fail, try to salvage substring between first { and last }\n",
    "    def parse_json_payload(s: str):\n",
    "        try:\n",
    "            return json.loads(s)\n",
    "        except json.JSONDecodeError:\n",
    "            start = s.find(\"{\")\n",
    "            end = s.rfind(\"}\")\n",
    "            if start != -1 and end != -1 and end > start:\n",
    "                try:\n",
    "                    return json.loads(s[start : end + 1])\n",
    "                except json.JSONDecodeError:\n",
    "                    return None\n",
    "            return None\n",
    "\n",
    "    parsed = parse_json_payload(content)\n",
    "    if not isinstance(parsed, dict):\n",
    "        return make_fallback(content or \"Model returned non-JSON output.\")\n",
    "\n",
    "    sentiment = normalize_sentiment(parsed.get(\"sentiment\", \"neutral\"))\n",
    "    if sentiment not in allowed:\n",
    "        sentiment = \"neutral\"\n",
    "\n",
    "    justification = trim_words(parsed.get(\"justification\", \"\"))\n",
    "    related_industry_naics = to_string_list(parsed.get(\"related_industry_naics\"))\n",
    "    related_company_names = to_string_list(parsed.get(\"related_company_names\"))\n",
    "\n",
    "    return {\n",
    "        \"sentiment\": sentiment,\n",
    "        \"justification\": justification,\n",
    "        \"related_industry_naics\": related_industry_naics,\n",
    "        \"related_company_names\": related_company_names,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d943537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:45<00:00,  9.10s/it]\n"
     ]
    }
   ],
   "source": [
    "# Refactored sampling loop compatible with the updated prompt and analyse_sentiment()\n",
    "\n",
    "required_columns = {\"text\", \"title\"}\n",
    "missing = required_columns - set(dfnews.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "sample_size = min(len(dfnews), 5)\n",
    "sentiment_samples: list[dict] = []\n",
    "\n",
    "if sample_size > 0:\n",
    "    # Sample rows and iterate directly to avoid Series/DataFrame ambiguity on duplicated index\n",
    "    sample_df = dfnews.sample(n=sample_size, random_state=0)\n",
    "\n",
    "    def _to_str(x) -> str:\n",
    "        if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "            return \"\"\n",
    "        return str(x)\n",
    "\n",
    "    max_chars = 5000  # prevent overly long inputs to the model\n",
    "\n",
    "    for row in tqdm(sample_df.itertuples(index=True), total=sample_size):\n",
    "        try:\n",
    "            title = _to_str(getattr(row, \"title\", \"\")).strip()\n",
    "            body = _to_str(getattr(row, \"text\", \"\")).strip()\n",
    "\n",
    "            # Combine title and body to improve context for Korean articles\n",
    "            combined_text = (title + \"\\n\\n\" + body).strip() if (title or body) else \"\"\n",
    "            if len(combined_text) > max_chars:\n",
    "                combined_text = combined_text[:max_chars]\n",
    "\n",
    "            result = analyse_sentiment(combined_text) if combined_text else {\n",
    "                \"sentiment\": \"neutral\",\n",
    "                \"justification\": \"No content provided.\",\n",
    "                \"related_industry_naics\": [],\n",
    "                \"related_company_names\": [],\n",
    "            }\n",
    "\n",
    "            sentiment_samples.append({\n",
    "                \"index\": row.Index,\n",
    "                \"headline\": title,\n",
    "                \"sentiment\": result.get(\"sentiment\", \"neutral\"),\n",
    "                \"justification\": result.get(\"justification\", \"\"),\n",
    "                \"related_industry_naics\": result.get(\"related_industry_naics\", []),\n",
    "                \"related_company_names\": result.get(\"related_company_names\", []),\n",
    "            })\n",
    "        except Exception as exc:\n",
    "            # Per-row fail-safe so one bad row doesn't stop the loop\n",
    "            sentiment_samples.append({\n",
    "                \"index\": row.Index,\n",
    "                \"headline\": _to_str(getattr(row, \"title\", \"\")).strip(),\n",
    "                \"sentiment\": \"neutral\",\n",
    "                \"justification\": f\"Processing error: {exc}\",\n",
    "                \"related_industry_naics\": [],\n",
    "                \"related_company_names\": [],\n",
    "            })\n",
    "else:\n",
    "    sentiment_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeb72791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 1462049,\n",
       " 'headline': \"AIBIZ, 세미콘웨스트 3년 연속 참가.. '글로벌 반도체 협력 모색'\",\n",
       " 'sentiment': 'positive',\n",
       " 'justification': \"AIBIZ's continued participation in SEMICON WEST and positive reception of its AI solutions suggest increased collaboration potential and standardization efforts, likely supporting modest growth.\",\n",
       " 'related_industry_naics': ['541715 - Research and Development in the Physical, Engineering, and Life Sciences',\n",
       "  '334413 - Semiconductor and Related Device Manufacturing',\n",
       "  '511210 - Software Publishers'],\n",
       " 'related_company_names': ['AIBIZ']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_samples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = os.path.join('/rdrive/rtrs_news', f'{parquet_file[:-8]}.sentiment.parquet')\n",
    "pd.DataFrame(sentiment_samples).to_parquet(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2e08d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>headline</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>justification</th>\n",
       "      <th>related_industry_naics</th>\n",
       "      <th>related_company_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1218843</td>\n",
       "      <td>'도시문제' 해결책 찾아…충남혁신센터-천안시, 스타트업 발굴</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The announcement details a startup support pro...</td>\n",
       "      <td>[541511 - Custom Computer Programming Services...</td>\n",
       "      <td>[Chungnam Creative Economy Innovation Center, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462049</td>\n",
       "      <td>AIBIZ, 세미콘웨스트 3년 연속 참가.. '글로벌 반도체 협력 모색'</td>\n",
       "      <td>positive</td>\n",
       "      <td>AIBIZ's continued participation in SEMICON WES...</td>\n",
       "      <td>[541715 - Research and Development in the Phys...</td>\n",
       "      <td>[AIBIZ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1276109</td>\n",
       "      <td>'어린이 위협 시구' 논란 최현욱, 자필 편지로 사과 전할까</td>\n",
       "      <td>negative</td>\n",
       "      <td>The incident involving a potentially dangerous...</td>\n",
       "      <td>[711110 - Performing Arts Companies, 511110 - ...</td>\n",
       "      <td>[SSG 랜더스, 삼성 라이온즈]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78750</td>\n",
       "      <td>추석 車보험 사고 피해자 1.6배 증가…“차간 거리 유지해야”</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The article reports an increase in car insuran...</td>\n",
       "      <td>[524113 - Direct Life, Health, and Medical Ins...</td>\n",
       "      <td>[Insurance Development Institute, General Insu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1296545</td>\n",
       "      <td>삼성도 찜한 혈액 진단…\"한국선 '통행세' 내야 해\" 기업들 해외로</td>\n",
       "      <td>negative</td>\n",
       "      <td>규제 미비로 인해 국내 체외진단 기업들이 해외 투자 유치 및 사업 확장에 어려움을 ...</td>\n",
       "      <td>[334516 - Analytical Laboratory Services, 6215...</td>\n",
       "      <td>[삼성물산, 삼성바이오로직스, 삼성바이오에피스, C2N 다이그노스틱스]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                  headline sentiment  \\\n",
       "0  1218843         '도시문제' 해결책 찾아…충남혁신센터-천안시, 스타트업 발굴   neutral   \n",
       "1  1462049  AIBIZ, 세미콘웨스트 3년 연속 참가.. '글로벌 반도체 협력 모색'  positive   \n",
       "2  1276109         '어린이 위협 시구' 논란 최현욱, 자필 편지로 사과 전할까  negative   \n",
       "3    78750        추석 車보험 사고 피해자 1.6배 증가…“차간 거리 유지해야”   neutral   \n",
       "4  1296545     삼성도 찜한 혈액 진단…\"한국선 '통행세' 내야 해\" 기업들 해외로  negative   \n",
       "\n",
       "                                       justification  \\\n",
       "0  The announcement details a startup support pro...   \n",
       "1  AIBIZ's continued participation in SEMICON WES...   \n",
       "2  The incident involving a potentially dangerous...   \n",
       "3  The article reports an increase in car insuran...   \n",
       "4  규제 미비로 인해 국내 체외진단 기업들이 해외 투자 유치 및 사업 확장에 어려움을 ...   \n",
       "\n",
       "                              related_industry_naics  \\\n",
       "0  [541511 - Custom Computer Programming Services...   \n",
       "1  [541715 - Research and Development in the Phys...   \n",
       "2  [711110 - Performing Arts Companies, 511110 - ...   \n",
       "3  [524113 - Direct Life, Health, and Medical Ins...   \n",
       "4  [334516 - Analytical Laboratory Services, 6215...   \n",
       "\n",
       "                               related_company_names  \n",
       "0  [Chungnam Creative Economy Innovation Center, ...  \n",
       "1                                            [AIBIZ]  \n",
       "2                                 [SSG 랜더스, 삼성 라이온즈]  \n",
       "3  [Insurance Development Institute, General Insu...  \n",
       "4            [삼성물산, 삼성바이오로직스, 삼성바이오에피스, C2N 다이그노스틱스]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = pd.DataFrame(sentiment_samples)\n",
    "dfres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc235b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guid                   tag:reuters.com,2025-10-01:newsml_EDY000694:1\n",
       "version_created                             2025-10-01T03:00:49.035Z\n",
       "title                             추석 車보험 사고 피해자 1.6배 증가…“차간 거리 유지해야”\n",
       "lang_code                                                         ko\n",
       "subject_qcodes                                          M:1QD, M:2CX\n",
       "content            \\r\\n[이데일리 김형일 기자] 추석 당일 자동차보험 사고 피해자가 1.6배 증가한...\n",
       "src                                                             3PTY\n",
       "ids                                                            78750\n",
       "text               추석 車보험 사고 피해자 1.6배 증가…“차간 거리 유지해야”\\n\\n\\r\\n[이데일...\n",
       "Name: 78750, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews.loc[78750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd5a53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral    5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres = pd.DataFrame(sentiment_samples) if sentiment_samples else pd.DataFrame(columns=[\"index\", \"headline\", \"sentiment\", \"justification\"])\n",
    "dfres"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaioss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
